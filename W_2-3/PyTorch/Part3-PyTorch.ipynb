{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3084, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784,128), nn.ReLU(), nn.Linear(128,64), nn.ReLU(), nn.Linear(64,10))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.view(images.shape[0], -1)\n",
    "logits = model(images)\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2975, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784,128), nn.ReLU(), nn.Linear(128,64), nn.ReLU(), nn.Linear(64,10), nn.LogSoftmax(dim = 1))\n",
    "\n",
    "# TODO: Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.view(images.shape[0], -1)\n",
    "logits = model(images)\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0036, -0.5645],\n",
      "        [ 0.5003, -0.8814]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x000001DA95610460>\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([[ 0.0018, -0.2822],\n",
      "        [ 0.2501, -0.4407]])\n",
      "tensor([[ 0.0036, -0.5645],\n",
      "        [ 0.5003, -0.8814]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(x.grad)\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[ 0.0045,  0.0045,  0.0045,  ...,  0.0045,  0.0045,  0.0045],\n",
      "        [ 0.0011,  0.0011,  0.0011,  ...,  0.0011,  0.0011,  0.0011],\n",
      "        [-0.0014, -0.0014, -0.0014,  ..., -0.0014, -0.0014, -0.0014],\n",
      "        ...,\n",
      "        [-0.0003, -0.0003, -0.0003,  ..., -0.0003, -0.0003, -0.0003],\n",
      "        [ 0.0068,  0.0068,  0.0068,  ...,  0.0068,  0.0068,  0.0068],\n",
      "        [ 0.0019,  0.0019,  0.0019,  ...,  0.0019,  0.0019,  0.0019]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intial weights - Parameter containing:\n",
      "tensor([[-0.0148,  0.0179, -0.0317,  ..., -0.0160,  0.0206,  0.0102],\n",
      "        [ 0.0124, -0.0350, -0.0317,  ..., -0.0116, -0.0186, -0.0029],\n",
      "        [ 0.0162, -0.0270,  0.0120,  ..., -0.0052, -0.0203, -0.0061],\n",
      "        ...,\n",
      "        [-0.0083,  0.0187,  0.0257,  ...,  0.0018,  0.0022, -0.0254],\n",
      "        [-0.0111,  0.0099, -0.0187,  ...,  0.0108,  0.0114, -0.0154],\n",
      "        [ 0.0258,  0.0233, -0.0156,  ...,  0.0123, -0.0321,  0.0229]],\n",
      "       requires_grad=True)\n",
      "gradient- tensor([[-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
      "        [-0.0004, -0.0004, -0.0004,  ..., -0.0004, -0.0004, -0.0004],\n",
      "        [-0.0009, -0.0009, -0.0009,  ..., -0.0009, -0.0009, -0.0009],\n",
      "        ...,\n",
      "        [-0.0008, -0.0008, -0.0008,  ..., -0.0008, -0.0008, -0.0008],\n",
      "        [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
      "        [ 0.0001,  0.0001,  0.0001,  ...,  0.0001,  0.0001,  0.0001]])\n",
      "optimised weights Parameter containing:\n",
      "tensor([[-0.0148,  0.0179, -0.0317,  ..., -0.0160,  0.0206,  0.0102],\n",
      "        [ 0.0124, -0.0350, -0.0317,  ..., -0.0116, -0.0186, -0.0029],\n",
      "        [ 0.0162, -0.0270,  0.0120,  ..., -0.0052, -0.0203, -0.0061],\n",
      "        ...,\n",
      "        [-0.0083,  0.0187,  0.0258,  ...,  0.0018,  0.0022, -0.0254],\n",
      "        [-0.0111,  0.0099, -0.0187,  ...,  0.0108,  0.0114, -0.0154],\n",
      "        [ 0.0258,  0.0233, -0.0156,  ...,  0.0123, -0.0321,  0.0229]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Intial weights -\",model[0].weight)\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images.resize_(64, 784)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "output = model(images)\n",
    "loss = criterion(output,labels)\n",
    "loss.backward()\n",
    "print(\"gradient-\", model[0].weight.grad)\n",
    "optimizer.step()\n",
    "print(\"optimised weights\", model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimised weights Parameter containing:\n",
      "tensor([[-0.0148,  0.0179, -0.0317,  ..., -0.0160,  0.0206,  0.0102],\n",
      "        [ 0.0124, -0.0350, -0.0317,  ..., -0.0116, -0.0186, -0.0029],\n",
      "        [ 0.0162, -0.0270,  0.0120,  ..., -0.0052, -0.0203, -0.0061],\n",
      "        ...,\n",
      "        [-0.0083,  0.0187,  0.0257,  ...,  0.0018,  0.0022, -0.0254],\n",
      "        [-0.0111,  0.0099, -0.0187,  ...,  0.0108,  0.0114, -0.0154],\n",
      "        [ 0.0258,  0.0233, -0.0156,  ...,  0.0123, -0.0321,  0.0229]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer.step()\n",
    "print(\"optimised weights\", model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9305082241863585\n",
      "Training loss: 0.8868054437484822\n",
      "Training loss: 0.532507248715297\n",
      "Training loss: 0.43182582889538584\n",
      "Training loss: 0.38647350848420087\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(images)\n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
