{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# import helper\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to C:\\Users\\HP/.pytorch/MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c1c6a644f446d6a3042235ec9796a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting C:\\Users\\HP/.pytorch/MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to C:\\Users\\HP/.pytorch/MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to C:\\Users\\HP/.pytorch/MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc09c37416a4ef18a3be426b8813cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting C:\\Users\\HP/.pytorch/MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to C:\\Users\\HP/.pytorch/MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to C:\\Users\\HP/.pytorch/MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to C:\\Users\\HP/.pytorch/MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41aefa72950b4708861a4689d92ac245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting C:\\Users\\HP/.pytorch/MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to C:\\Users\\HP/.pytorch/MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to C:\\Users\\HP/.pytorch/MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53c3b5f8d284498b6bc2e54816a5f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting C:\\Users\\HP/.pytorch/MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to C:\\Users\\HP/.pytorch/MNIST_data/MNIST\\raw\n",
      "\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def multi_layer_NW(inputUnits, hiddenUnits, outputUnits):\n",
    "    torch.manual_seed(7)\n",
    "    n_input = inputUnits\n",
    "    n_hidden = hiddenUnits\n",
    "    n_output = outputUnits\n",
    "    \n",
    "    W1 = torch.randn(n_input, n_hidden)\n",
    "    W2 = torch.randn(n_hidden, n_output)\n",
    "    \n",
    "    B1 = torch.randn((1, n_hidden))\n",
    "    B2 = torch.randn((1, n_output))\n",
    "    \n",
    "    return W1, W2, B1, B2\n",
    "\n",
    "\n",
    "def calc_output(features,W1,W2,B1,B2):\n",
    "    h = activation(torch.matmul(features,W1).add_(B1))\n",
    "    output = activation(torch.matmul(h,W2).add_(B2))\n",
    "    return output\n",
    "\n",
    "features = torch.flatten(images,start_dim=1)\n",
    "W1,W2,B1,B2 = multi_layer_NW(features.shape[1],256,10)\n",
    "\n",
    "out = calc_output(features,W1,W2,B1,B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([0.0141, 0.0147, 0.0169, 0.0155, 0.0140, 0.0165, 0.0152, 0.0165, 0.0145,\n",
      "        0.0157, 0.0163, 0.0166, 0.0148, 0.0137, 0.0150, 0.0171, 0.0171, 0.0147,\n",
      "        0.0166, 0.0161, 0.0199, 0.0139, 0.0156, 0.0157, 0.0156, 0.0168, 0.0144,\n",
      "        0.0149, 0.0172, 0.0157, 0.0151, 0.0178, 0.0139, 0.0154, 0.0141, 0.0154,\n",
      "        0.0150, 0.0144, 0.0165, 0.0155, 0.0165, 0.0152, 0.0137, 0.0150, 0.0162,\n",
      "        0.0146, 0.0151, 0.0154, 0.0165, 0.0132, 0.0180, 0.0150, 0.0157, 0.0136,\n",
      "        0.0166, 0.0159, 0.0166, 0.0182, 0.0166, 0.0142, 0.0147, 0.0185, 0.0149,\n",
      "        0.0153])\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    ## TODO: Implement the softmax function here\n",
    "    return (torch.exp(x) / torch.sum(torch.exp(x)))\n",
    "\n",
    "# Here, out should be the output of the network in the previous excercise with shape (64,10)\n",
    "probabilities = softmax(out)\n",
    "\n",
    "# Does it have the right shape? Should be (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Does it sum to 1?\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building networks with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concise way of creating the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        self.output = nn.Linear(256,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        x = F.softmax(self.output(x), dim = 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a network with 784 input units, a hidden layer with 128 units and a ReLU activation, then a hidden layer with 64 units and a ReLU activation, and finally an output layer with a softmax activation as shown above. You can use a ReLU activation with the nn.ReLU module or F.relu function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784,128)\n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        self.fc3 = nn.Linear(64,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim = 1)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0108, -0.0064,  0.0180,  ..., -0.0278,  0.0283, -0.0150],\n",
      "        [ 0.0291,  0.0183,  0.0342,  ..., -0.0020,  0.0213,  0.0130],\n",
      "        [-0.0093,  0.0075, -0.0322,  ...,  0.0134, -0.0202, -0.0192],\n",
      "        ...,\n",
      "        [ 0.0352, -0.0348, -0.0265,  ...,  0.0357,  0.0334, -0.0287],\n",
      "        [-0.0336, -0.0091,  0.0264,  ...,  0.0061, -0.0121, -0.0265],\n",
      "        [ 0.0086, -0.0050,  0.0048,  ...,  0.0030, -0.0192,  0.0269]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0217, -0.0288, -0.0096, -0.0354,  0.0053,  0.0124,  0.0284, -0.0118,\n",
      "        -0.0292, -0.0308, -0.0319, -0.0209,  0.0240, -0.0110, -0.0122, -0.0269,\n",
      "         0.0055,  0.0277,  0.0021,  0.0227,  0.0272,  0.0029,  0.0168, -0.0080,\n",
      "         0.0085,  0.0199, -0.0241,  0.0007,  0.0068,  0.0188,  0.0105,  0.0320,\n",
      "        -0.0327,  0.0204, -0.0081,  0.0114, -0.0029,  0.0004,  0.0228, -0.0137,\n",
      "        -0.0342, -0.0162,  0.0245,  0.0011,  0.0273,  0.0011,  0.0314,  0.0140,\n",
      "         0.0234,  0.0255, -0.0084,  0.0137,  0.0194,  0.0017, -0.0002, -0.0031,\n",
      "        -0.0297, -0.0152,  0.0041, -0.0290, -0.0279,  0.0310, -0.0214,  0.0317,\n",
      "        -0.0049, -0.0264, -0.0305, -0.0215,  0.0244, -0.0206,  0.0019,  0.0290,\n",
      "        -0.0266,  0.0289,  0.0202,  0.0326,  0.0272, -0.0245,  0.0021,  0.0221,\n",
      "         0.0084, -0.0057, -0.0155,  0.0147,  0.0109, -0.0258,  0.0193,  0.0124,\n",
      "        -0.0288,  0.0061, -0.0349,  0.0343, -0.0059,  0.0218, -0.0070,  0.0203,\n",
      "        -0.0147,  0.0129,  0.0039,  0.0349,  0.0011, -0.0187,  0.0161,  0.0107,\n",
      "        -0.0027, -0.0319,  0.0220, -0.0054,  0.0096,  0.0138,  0.0217, -0.0167,\n",
      "        -0.0060,  0.0040, -0.0153, -0.0125,  0.0137, -0.0085,  0.0166,  0.0265,\n",
      "        -0.0347, -0.0111,  0.0034, -0.0178,  0.0351,  0.0050,  0.0297, -0.0333],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(model.fc1.weight)\n",
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.6653e-02, -1.3110e-02, -8.6029e-03,  ...,  1.7131e-03,\n",
      "         -9.0008e-03,  6.2851e-03],\n",
      "        [ 1.6517e-03, -1.2334e-02,  1.2620e-02,  ..., -6.7218e-03,\n",
      "          9.6172e-03,  9.2312e-03],\n",
      "        [-4.9155e-03, -7.0677e-03,  1.7903e-02,  ...,  1.1409e-02,\n",
      "         -7.6191e-05, -8.3350e-03],\n",
      "        ...,\n",
      "        [-6.2382e-03, -4.2531e-03, -1.9434e-03,  ...,  7.1445e-03,\n",
      "         -3.6215e-03, -2.0718e-02],\n",
      "        [-1.3748e-02,  1.4426e-03, -1.1504e-02,  ...,  5.7599e-03,\n",
      "          8.2837e-03,  2.3810e-02],\n",
      "        [-2.5513e-02, -1.1169e-02, -1.4988e-02,  ..., -5.3088e-03,\n",
      "         -2.1968e-02, -1.0001e-02]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model.fc1.bias.data.fill_(0)\n",
    "model.fc1.weight.data.normal_(std=0.01)\n",
    "print(model.fc1.weight)\n",
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "images.resize_(64, 1, 784)\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)\n",
    "\n",
    "# Forward pass through the network and display output\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "# helper.view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "passing in an OrderedDict to name the individual layers and operations, instead of using incremental integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "                      ('relu2', nn.ReLU()),\n",
    "                      ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "                      ('softmax', nn.Softmax(dim=1))]))\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
