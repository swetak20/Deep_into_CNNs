{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import utilities\n",
    "import fc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 231,
       "width": 231
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "utilities.imshow(image[0,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fc_model.Network(784, 10, [512, 256, 128])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2..  Training Loss: 1.737..  Test Loss: 0.972..  Test Accuracy: 0.597\n",
      "Epoch: 1/2..  Training Loss: 1.014..  Test Loss: 0.714..  Test Accuracy: 0.723\n",
      "Epoch: 1/2..  Training Loss: 0.858..  Test Loss: 0.675..  Test Accuracy: 0.750\n",
      "Epoch: 1/2..  Training Loss: 0.792..  Test Loss: 0.632..  Test Accuracy: 0.759\n",
      "Epoch: 1/2..  Training Loss: 0.739..  Test Loss: 0.612..  Test Accuracy: 0.761\n",
      "Epoch: 1/2..  Training Loss: 0.740..  Test Loss: 0.596..  Test Accuracy: 0.776\n",
      "Epoch: 1/2..  Training Loss: 0.684..  Test Loss: 0.592..  Test Accuracy: 0.783\n",
      "Epoch: 1/2..  Training Loss: 0.680..  Test Loss: 0.581..  Test Accuracy: 0.780\n",
      "Epoch: 1/2..  Training Loss: 0.656..  Test Loss: 0.555..  Test Accuracy: 0.800\n",
      "Epoch: 1/2..  Training Loss: 0.667..  Test Loss: 0.561..  Test Accuracy: 0.794\n",
      "Epoch: 1/2..  Training Loss: 0.635..  Test Loss: 0.554..  Test Accuracy: 0.792\n",
      "Epoch: 1/2..  Training Loss: 0.652..  Test Loss: 0.544..  Test Accuracy: 0.800\n",
      "Epoch: 1/2..  Training Loss: 0.600..  Test Loss: 0.538..  Test Accuracy: 0.804\n",
      "Epoch: 1/2..  Training Loss: 0.606..  Test Loss: 0.519..  Test Accuracy: 0.809\n",
      "Epoch: 1/2..  Training Loss: 0.627..  Test Loss: 0.552..  Test Accuracy: 0.795\n",
      "Epoch: 1/2..  Training Loss: 0.602..  Test Loss: 0.503..  Test Accuracy: 0.815\n",
      "Epoch: 1/2..  Training Loss: 0.580..  Test Loss: 0.516..  Test Accuracy: 0.809\n",
      "Epoch: 1/2..  Training Loss: 0.634..  Test Loss: 0.506..  Test Accuracy: 0.819\n",
      "Epoch: 1/2..  Training Loss: 0.564..  Test Loss: 0.500..  Test Accuracy: 0.813\n",
      "Epoch: 1/2..  Training Loss: 0.563..  Test Loss: 0.493..  Test Accuracy: 0.820\n",
      "Epoch: 1/2..  Training Loss: 0.604..  Test Loss: 0.495..  Test Accuracy: 0.822\n",
      "Epoch: 1/2..  Training Loss: 0.565..  Test Loss: 0.493..  Test Accuracy: 0.817\n",
      "Epoch: 1/2..  Training Loss: 0.592..  Test Loss: 0.489..  Test Accuracy: 0.823\n",
      "Epoch: 2/2..  Training Loss: 0.550..  Test Loss: 0.508..  Test Accuracy: 0.812\n",
      "Epoch: 2/2..  Training Loss: 0.566..  Test Loss: 0.469..  Test Accuracy: 0.826\n",
      "Epoch: 2/2..  Training Loss: 0.538..  Test Loss: 0.483..  Test Accuracy: 0.828\n",
      "Epoch: 2/2..  Training Loss: 0.531..  Test Loss: 0.483..  Test Accuracy: 0.826\n",
      "Epoch: 2/2..  Training Loss: 0.541..  Test Loss: 0.503..  Test Accuracy: 0.823\n",
      "Epoch: 2/2..  Training Loss: 0.577..  Test Loss: 0.476..  Test Accuracy: 0.823\n",
      "Epoch: 2/2..  Training Loss: 0.563..  Test Loss: 0.478..  Test Accuracy: 0.830\n",
      "Epoch: 2/2..  Training Loss: 0.521..  Test Loss: 0.466..  Test Accuracy: 0.828\n",
      "Epoch: 2/2..  Training Loss: 0.516..  Test Loss: 0.461..  Test Accuracy: 0.829\n",
      "Epoch: 2/2..  Training Loss: 0.553..  Test Loss: 0.461..  Test Accuracy: 0.831\n",
      "Epoch: 2/2..  Training Loss: 0.509..  Test Loss: 0.452..  Test Accuracy: 0.837\n",
      "Epoch: 2/2..  Training Loss: 0.526..  Test Loss: 0.452..  Test Accuracy: 0.836\n",
      "Epoch: 2/2..  Training Loss: 0.537..  Test Loss: 0.476..  Test Accuracy: 0.825\n",
      "Epoch: 2/2..  Training Loss: 0.491..  Test Loss: 0.456..  Test Accuracy: 0.837\n",
      "Epoch: 2/2..  Training Loss: 0.531..  Test Loss: 0.452..  Test Accuracy: 0.837\n",
      "Epoch: 2/2..  Training Loss: 0.506..  Test Loss: 0.482..  Test Accuracy: 0.822\n",
      "Epoch: 2/2..  Training Loss: 0.547..  Test Loss: 0.450..  Test Accuracy: 0.833\n",
      "Epoch: 2/2..  Training Loss: 0.540..  Test Loss: 0.435..  Test Accuracy: 0.838\n",
      "Epoch: 2/2..  Training Loss: 0.514..  Test Loss: 0.458..  Test Accuracy: 0.833\n",
      "Epoch: 2/2..  Training Loss: 0.512..  Test Loss: 0.444..  Test Accuracy: 0.835\n",
      "Epoch: 2/2..  Training Loss: 0.547..  Test Loss: 0.448..  Test Accuracy: 0.833\n",
      "Epoch: 2/2..  Training Loss: 0.523..  Test Loss: 0.444..  Test Accuracy: 0.841\n",
      "Epoch: 2/2..  Training Loss: 0.522..  Test Loss: 0.439..  Test Accuracy: 0.836\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fc_model.train(model, trainloader, testloader, criterion, optimizer, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: \n",
      "\n",
      " Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ") \n",
      "\n",
      "The state dict keys: \n",
      "\n",
      " odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param with shape torch.Size([512, 784]) from checkpoint, the shape in current model is torch.Size([400, 784]).\n\tsize mismatch for hidden_layers.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([400]).\n\tsize mismatch for hidden_layers.1.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([200, 400]).\n\tsize mismatch for hidden_layers.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for hidden_layers.2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([100, 200]).\n\tsize mismatch for hidden_layers.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([100]).\n\tsize mismatch for output.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 100]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d859c59ebec0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfc_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# This will throw an error because the tensor sizes are wrong!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1223\u001b[1;33m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[0;32m   1224\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0;32m   1225\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param with shape torch.Size([512, 784]) from checkpoint, the shape in current model is torch.Size([400, 784]).\n\tsize mismatch for hidden_layers.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([400]).\n\tsize mismatch for hidden_layers.1.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([200, 400]).\n\tsize mismatch for hidden_layers.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for hidden_layers.2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([100, 200]).\n\tsize mismatch for hidden_layers.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([100]).\n\tsize mismatch for output.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 100])."
     ]
    }
   ],
   "source": [
    "# Try this\n",
    "model = fc_model.Network(784, 10, [400, 200, 100])\n",
    "# This will throw an error because the tensor sizes are wrong!\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = fc_model.Network(checkpoint['input_size'],\n",
    "                             checkpoint['output_size'],\n",
    "                             checkpoint['hidden_layers'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
      "    (1): Linear(in_features=400, out_features=200, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = load_checkpoint('checkpoint.pth')\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
